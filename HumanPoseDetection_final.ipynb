{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Posture Detection\n",
    "In this example, we show how the MAX-Human-Pose-Estimator model can be used to detect and visualize the human poses from an image.\n",
    "\n",
    "## Contents of this code\n",
    "We first visualize the test image and pass it through the MAX-Human-Pose-Estimator model to get all the human poses (a group of lines for each person in a JSON format). We then visualize the detected poses to verify that the model worked as intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.helpers import draw_pose, get_pose_from_file, convert_pose\n",
    "from utils.train import train_svm_classifier\n",
    "from utils.data import process_images, fill_empty_vector, flatten_dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process images to the numpy format\n",
    "Turn images stored in assets/images into numpy files stored in assets/poses.\n",
    "Images of the same class must be stored in their own subdirectories in the assets/images directory.\n",
    "\n",
    "The *process_images* function goes through all of the directories in the assets/images folder, processing all of the images in each folder. \n",
    "\n",
    "The *get_pose_from_file* function takes the specified image and sends it to the MAX Model for prediction. \n",
    "The model returns a prediction of shape [num_lines, x, y] where x and y define the Cartesian coordinates of the center of the predicted body part.\n",
    "\n",
    "The *save_pose* function takes these Cartesian predictions and saves the prediction as a numpy file. The *cartesian* parameter specifies whether or not to convert to polar coordinates. When converted to polar coordinates, the features are converted from from [x, y] to [rho, phi], a vector that points from the center of the pose to the specified coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(cartesian=False):\n",
    "    \"\"\"\n",
    "    Extracts features and labels from assets/images directory\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    lines = []\n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "\n",
    "    for x in os.walk(str(os.getcwd())+'/assets/images'):\n",
    "        for d in x[1]:\n",
    "            if d != 'test':\n",
    "                print('processing images in {}'.format(d))\n",
    "                for f in os.listdir(str(os.getcwd())+'/assets/images/'+d):\n",
    "                    try:\n",
    "                        preds, img = get_pose_from_file(f, d)\n",
    "                        \n",
    "                        if preds['predictions']:\n",
    "                            for i in range(len(preds['predictions'])):\n",
    "                                pose_lines = preds['predictions'][i]['pose_lines']\n",
    "                                body_parts = preds['predictions'][i]['body_parts']\n",
    "                                coordinates = np.array([[d['x'], d['y']] for d in body_parts], dtype=np.float32)\n",
    "                                p = convert_pose(coordinates, cartesian=cartesian)\n",
    "\n",
    "                                if p != []:\n",
    "                                    p = fill_empty_vector(p)\n",
    "                                    features.append(p)\n",
    "                                    labels.append(d)\n",
    "                                    lines.append(pose_lines)\n",
    "\n",
    "                    except Exception:\n",
    "                        print(\"Something went wrong\")\n",
    "                        traceback.print_exc()\n",
    "                        break\n",
    "\n",
    "    return np.array(features), labels, np.array(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features, labels, lines = process_images(cartesian=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the data\n",
    "Adding more data helps our model generalize a little bit. Tweak the data_size and noise_amount values to change how noisy the poses should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the features and labels and add noise to them until each class reaches data_size\n",
    "def augment_data(features, labels, data_size=15,noise_amount=0.03):\n",
    "    print('\\n--- Augmenting Data ---\\n')\n",
    "    orig_labels_count = len(labels)\n",
    "    label_frequency = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    while sum(label_frequency[1]) < data_size * len(label_frequency[0]):\n",
    "        for i in range(orig_labels_count):\n",
    "            if label_frequency[1][np.where(label_frequency[0] == labels[i])] < data_size:\n",
    "                feature = features[i]\n",
    "                new_data = np.zeros(feature.shape,dtype=np.float32)\n",
    "                \n",
    "                # add noise to each body part, making sure to add the same noise to corresponding joints\n",
    "                for k, part in enumerate(feature):\n",
    "                    noise = np.random.normal(0, noise_amount, 2)\n",
    "                    new_0 = part[0] + noise[0]\n",
    "                    new_1 = part[1] + noise[1]\n",
    "                    new_data[k] = [new_0, new_1]\n",
    "\n",
    "                features = np.concatenate((features, np.expand_dims(new_data,axis=0)))\n",
    "                labels.append(labels[i])\n",
    "            label_frequency = np.unique(labels, return_counts=True)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "# OPTIMAL PARAMETERS\n",
    "data_size, noise = 100, 0.05\n",
    "f_aug, l_aug = augment_data(features, labels, data_size=data_size, noise_amount=noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.DataFrame(columns=['Class','Nose_x','Nose_y',\n",
    "    'Neck_x','Neck_y',\n",
    "    'RShoulder_x','RShoulder_y',\n",
    "    'RElbow_x','RElbow_y',\n",
    "    'RWrist_x','RWrist_y',\n",
    "    'LShoulder_x','LShoulder_y',\n",
    "    'LElbow_x','LElbow_y',\n",
    "    'LWrist_x','LWrist_y',\n",
    "    'RHip_x','RHip_y',\n",
    "    'RKnee_x','RKnee_y',\n",
    "    'RAnkle_x','RAnkle_y',\n",
    "    'LHip_x','LHip_y',\n",
    "    'LKnee_x','LKnee_y',\n",
    "    'LAnkle_x','LAnkle_y',\n",
    "    'REye_x','REye_y',\n",
    "    'LEye_x','LEye_y',\n",
    "    'REar_x','REar_y',\n",
    "    'LEar_x','LEar_y'])\n",
    "\n",
    "df['Class'] = l_aug\n",
    "\n",
    "for col in [name for name in df.columns if name != 'Class']:\n",
    "    if '_x' in col:\n",
    "        x = 0\n",
    "    else:\n",
    "        x = 1\n",
    "    idx = (df.columns.get_loc(col)) % 19\n",
    "    df[col] = f_aug[:,idx,x]\n",
    "    \n",
    "class_names = df['Class'].unique()\n",
    "#df['Class'] = pd.factorize(df['Class'])[0] + 1\n",
    "\n",
    "# separate features from target\n",
    "feats = [name for name in df.columns if name != 'Class']\n",
    "\n",
    "x = df.loc[:,feats].values\n",
    "y = df.loc[:,['Class']].values\n",
    "\n",
    "# standardize the features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(.95)\n",
    "\n",
    "# get principal components\n",
    "principal_components = pca.fit_transform(x)\n",
    "principal_df = pd.DataFrame(data = principal_components)\n",
    "final_df = pd.concat([principal_df, df[['Class']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the first two principal components so we can see how well the classes separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,11))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title(str('2 component PCA with data_size = {} noise = {}'.format(data_size, noise)), fontsize = 20)\n",
    "targets = class_names\n",
    "colors = ['aqua', 'magenta', 'navy', 'lime', 'red', 'blue', 'orange', 'yellow', 'maroon', 'coral','plum']\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = final_df['Class'] == target\n",
    "    ax.scatter(final_df.loc[indicesToKeep, 0],\n",
    "               final_df.loc[indicesToKeep, 1],\n",
    "               c = color, s = 50)\n",
    "    \n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the labels to feed it into SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    name_map = {key:val for key,val in zip(integer_encoded,labels)}\n",
    "    return np.array(integer_encoded), name_map\n",
    "\n",
    "labels_encoded, name_map = encode_labels(l_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ideal poses for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_pose(features, labels, name_map):\n",
    "    ideal_poses = {}\n",
    "    for lab, name in name_map.items():\n",
    "        feature_list = np.array([feats for i, feats in enumerate(features) if labels[i]==lab])\n",
    "        ideal_poses[name] = np.average(feature_list, axis=0)\n",
    "        \n",
    "    return ideal_poses\n",
    "\n",
    "ideal_poses = get_ideal_pose(f_aug, labels_encoded, name_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the polar coordinates for the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "for lab,name in name_map.items():\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(121 + lab%2, projection='polar')\n",
    "    ax.set_theta_zero_location(\"W\")\n",
    "    plt.title(str(name_map[lab]),loc='left')\n",
    "    feature_list = np.array([feats for i, feats in enumerate(f_aug) if labels_encoded[i]==lab])\n",
    "    for feat in feature_list:\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(feat[:,0])))\n",
    "        c = ax.scatter(feat[:,1],feat[:,0],cmap='hsv',alpha=0.75,c=colors)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the SVM!\n",
    "Take the augmented data/labels that we've generated, flatten the features vector, then pass into the SVM function for training.\n",
    "This will create */assets/classifier.pkl* which can be loaded at any time for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_flat = flatten_dataset(f_aug)\n",
    "print('augmented features shape: ', str(f_aug.shape))\n",
    "print('flattened features shape: ', str(features_flat.shape))\n",
    "print('encoded labels shape: ', str(labels_encoded.shape))\n",
    "classifier, svm = train_svm_classifier(features_flat, labels_encoded,'assets/classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the SVM using the data in the assets/images/test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "up = 0\n",
    "down = 0\n",
    "for img in os.listdir(str(os.getcwd())+'/assets/images/test'):\n",
    "    fig = plt.figure(figsize=(10,15))\n",
    "    # visualize the pose\n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    preds, frame = get_pose_from_file(img,'test')\n",
    "    bgr = np.array(cv2.imread('./assets/images/test/'+img))\n",
    "    pose_img = bgr[..., ::-1]\n",
    "    draw_pose(preds, bgr)\n",
    "    plt.imshow(pose_img)\n",
    "    plt.title(\"The detected poses\")\n",
    "    \n",
    "    # make predictions\n",
    "    body_parts = preds['predictions'][0]['body_parts']\n",
    "    coordinates = np.array([[d['x'], d['y']] for d in body_parts], dtype=np.float32)\n",
    "    pose = np.array(convert_pose(coordinates, cartesian=False))\n",
    "    x = flatten_dataset(np.expand_dims(fill_empty_vector(np.squeeze(pose)), axis=0))\n",
    "    p = classifier.predict(x)\n",
    "    prediction = name_map[p[0]]\n",
    "    confidence = classifier.predict_proba(x)\n",
    "    print('The prediction is {} with confidence {} %'.format(prediction, 100 * confidence[0][p[0]]))\n",
    "    print('The real pose is ', img.split('.')[0])\n",
    "\n",
    "    #Check percentage ------------------- Nihar\n",
    "    inside = str(prediction) in str(img.split('.')[0])\n",
    "    if inside:\n",
    "        up +=1\n",
    "        print(\"Tru Pred\")\n",
    "    else:\n",
    "        print(\"False Pred\")\n",
    "    down +=1\n",
    "    print(up,down)\n",
    "    # visualize the polar plot\n",
    "    ax = plt.subplot(1, 2, 2, projection='polar')\n",
    "    ax.set_theta_zero_location(\"W\")\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(pose[:,0])))\n",
    "    c = plt.scatter(pose[:, 1], pose[:, 0], cmap='hsv', alpha=0.75, c=colors)\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Test Accuracy:\",up/down*100)\n",
    "print(str(up) + \"/\" + str(down) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
